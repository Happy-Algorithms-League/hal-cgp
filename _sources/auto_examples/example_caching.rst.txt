.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_example_caching.py>`     to download the full example code
    .. rst-class:: sphx-glr-example-title

    .. _sphx_glr_auto_examples_example_caching.py:


Example demonstrating the use of the caching decorator.
=======================================================

Caches the results of fitness evaluations in a pickle file
('example_caching_cache.pkl'). To illustrate its practical use,
compare the runtime of this script when you first call it vs. the
second time and when you comment out the decorator on
`inner_objective`.


.. code-block:: default


    import time

    import numpy as np

    import cgp








We define the target function for this example.


.. code-block:: default



    def f_target(x):
        return x ** 2 + x + 1.0









We then define the objective function for the evolutionary
algorithm: It consists of an inner objective which we wrap with the
caching decorator. This decorator specifies a pickle file that will be used for
caching results of fitness evaluations. The inner objective is then used by the objective
function to compute (or retrieve from cache) the fitness of the individual.


.. code-block:: default



    @cgp.utils.disk_cache("example_caching_cache.pkl")
    def inner_objective(expr):
        """The caching decorator uses the function parameters to identify
        identical function calls. Here, as many different genotypes
        produce the same simplified SymPy expression we can use such
        expressions as an argument to the decorated function to avoid
        reevaluating functionally identical individuals.
        Note that caching only makes sense for deterministic objective
        functions, as it assumes that identical expressions will always
        return the same fitness values.

        """
        loss = []
        for x0 in np.linspace(-2.0, 2.0, 100):
            y = float(expr[0].subs({"x_0": x0}).evalf())
            loss.append((f_target(x0) - y) ** 2)

        time.sleep(0.25)  # emulate long fitness evaluation

        return np.mean(loss)


    def objective(individual):
        if individual.fitness is not None:
            return individual

        individual.fitness = -inner_objective(individual.to_sympy())

        return individual









Next, we define the parameters for the population, the genome of
individuals, and the evolutionary algorithm.


.. code-block:: default



    params = {
        "population_params": {"n_parents": 10, "mutation_rate": 0.05, "seed": 8188211},
        "ea_params": {"n_offsprings": 10, "tournament_size": 1, "n_processes": 1},
        "genome_params": {
            "n_inputs": 1,
            "n_outputs": 1,
            "n_columns": 10,
            "n_rows": 2,
            "levels_back": 2,
            "primitives": (cgp.Add, cgp.Sub, cgp.Mul, cgp.ConstantFloat),
        },
        "evolve_params": {"max_generations": 100, "min_fitness": -1e-12},
    }








We then create a Population instance and instantiate the evolutionary algorithm.


.. code-block:: default



    pop = cgp.Population(**params["population_params"], genome_params=params["genome_params"])
    ea = cgp.ea.MuPlusLambda(**params["ea_params"])








Finally, we call the `evolve` method to perform the evolutionary search.


.. code-block:: default



    cgp.evolve(pop, objective, ea, **params["evolve_params"], print_progress=True)


    print(f"evolved function: {pop.champion.to_sympy()}")




.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    [2/100] max fitness: -2.360269360269361[K    [3/100] max fitness: -2.360269360269361[K    [4/100] max fitness: -2.360269360269361[K    [5/100] max fitness: -1.0[K    [6/100] max fitness: -1.0[K    [7/100] max fitness: -1.0[K    [8/100] max fitness: -1.0[K    [9/100] max fitness: -1.0[K    [10/100] max fitness: -1.0[K    [11/100] max fitness: -1.0[K    [12/100] max fitness: -1.0[K    [13/100] max fitness: -1.0[K    [14/100] max fitness: -1.0[K    [15/100] max fitness: -1.0[K    [16/100] max fitness: -1.0[K    [17/100] max fitness: -1.0[K    [18/100] max fitness: -1.0[K    [19/100] max fitness: -1.0[K    [20/100] max fitness: -1.0[K    [21/100] max fitness: -1.0[K    [22/100] max fitness: -1.0[K    [23/100] max fitness: -1.0[K    [24/100] max fitness: -1.0[K    [25/100] max fitness: -1.0[K    [26/100] max fitness: -1.0[K    [27/100] max fitness: -1.0[K    [28/100] max fitness: -1.0[K    [29/100] max fitness: -1.0[K    [30/100] max fitness: -1.0[K    [31/100] max fitness: -1.0[K    [32/100] max fitness: -1.0[K    [33/100] max fitness: -1.0[K    [34/100] max fitness: -1.0[K    [35/100] max fitness: -1.0[K    [36/100] max fitness: -1.0[K    [37/100] max fitness: -1.0[K    [38/100] max fitness: -1.0[K    [39/100] max fitness: -1.0[K    [40/100] max fitness: -1.0[K    [41/100] max fitness: -1.0[K    [42/100] max fitness: -1.0[K    [43/100] max fitness: -1.0[K    [44/100] max fitness: -1.0[K    [45/100] max fitness: -1.0[K    [46/100] max fitness: -1.0[K    [47/100] max fitness: -1.0[K    [48/100] max fitness: -1.0[K    [49/100] max fitness: -1.0[K    [50/100] max fitness: -1.0[K    [51/100] max fitness: -1.0[K    [52/100] max fitness: -1.0[K    [53/100] max fitness: -1.0[K    [54/100] max fitness: -1.0[K    [55/100] max fitness: -1.0[K    [56/100] max fitness: -1.0[K    [57/100] max fitness: -1.0[K    [58/100] max fitness: -1.0[K    [59/100] max fitness: -1.0[K    [60/100] max fitness: -1.0[K    [61/100] max fitness: -1.0[K    [62/100] max fitness: -1.0[K    [63/100] max fitness: -1.0[K    [64/100] max fitness: -1.0[K    [65/100] max fitness: -1.0[K    [66/100] max fitness: -1.0[K    [67/100] max fitness: -1.0[K    [68/100] max fitness: -1.0[K    [69/100] max fitness: -1.0[K    [70/100] max fitness: -1.0[K    [71/100] max fitness: -1.0[K    [72/100] max fitness: -1.0[K    [73/100] max fitness: -1.0[K    [74/100] max fitness: -1.0[K    [75/100] max fitness: -1.0[K    [76/100] max fitness: -1.0[K    [77/100] max fitness: -1.0[K    [78/100] max fitness: -1.0[K    [79/100] max fitness: -1.0[K    [80/100] max fitness: -1.0[K    [81/100] max fitness: -1.0[K    [82/100] max fitness: -1.0[K    [83/100] max fitness: -1.0[K    [84/100] max fitness: -1.0[K    [85/100] max fitness: -1.0[K    [86/100] max fitness: -1.0[K    [87/100] max fitness: -1.0[K    [88/100] max fitness: -1.0[K    [89/100] max fitness: -1.0[K    [90/100] max fitness: -1.0[K    [91/100] max fitness: -1.0[K    [92/100] max fitness: -1.0[K    [93/100] max fitness: -1.0[K    [94/100] max fitness: -1.0[K    [95/100] max fitness: -1.0[K    [96/100] max fitness: -1.0[K    [97/100] max fitness: -1.0[K    [98/100] max fitness: -1.0[K    [99/100] max fitness: -1.0[K    [100/100] max fitness: -1.0[K
    evolved function: [x_0*(x_0 + 1)]





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  3.507 seconds)


.. _sphx_glr_download_auto_examples_example_caching.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: example_caching.py <example_caching.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: example_caching.ipynb <example_caching.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
